# ğŸš€ å¿«é€Ÿä¸‹è¼‰åƒè€ƒå¡

## æœ€å¸¸è¦‹çš„ 3 ç¨®ç”¨æ³•

### 1ï¸âƒ£ æœ€ç°¡å–® - ç›´æ¥ä¸‹è¼‰ open_llama_7b_v2-int4

```powershell
# æ¿€æ´»ç’°å¢ƒ
.\venv\Scripts\Activate.ps1

# ä¸€è¡Œå‘½ä»¤ä¸‹è¼‰ï¼ˆæ¨è–¦ï¼‰
python scripts/download_hf_model.py --repo-id "OpenVINO/open_llama_7b_v2-int4-ov"
```

**çµæœï¼š** æ¨¡å‹è‡ªå‹•ä¿å­˜åˆ° `./models/open_llama_7b_v2-int4-ov/`

---

### 2ï¸âƒ£ èœå–®é¸æ“‡ - å¾é è¨­åˆ—è¡¨é¸æ“‡

```powershell
# æ¿€æ´»ç’°å¢ƒ
.\venv\Scripts\Activate.ps1

# åŸ·è¡Œäº’å‹•å¼èœå–®
.\scripts\download_model_interactive.ps1
```

**èœå–®é¸é …ï¼š**
```
1) OpenLLaMA 7B (OpenVINO int4)       â† é¸æ“‡é€™å€‹
2) TinyLlama 1.1B (OpenVINO int4)
3) TinyLlama 1.1B (PyTorch)
4) Qwen 7B (OpenVINO)
5) è‡ªè¨‚æ¨¡å‹ï¼ˆæ‰‹å‹•è¼¸å…¥ï¼‰
```

---

### 3ï¸âƒ£ å®Œæ•´ç”¨æ³• - æŒ‡å®šå…¨éƒ¨åƒæ•¸

```powershell
python scripts/download_hf_model.py \
    --repo-id "OpenVINO/open_llama_7b_v2-int4-ov" \
    --model-name "open_llama_7b_v2-int4" \
    --output-dir "./models"
```

---

## ğŸ“‹ æ‰€æœ‰å¯ç”¨å‘½ä»¤

| éœ€æ±‚ | å‘½ä»¤ |
|------|------|
| **ä¸‹è¼‰ OpenLLaMA 7B** | `python scripts/download_hf_model.py --repo-id "OpenVINO/open_llama_7b_v2-int4-ov"` |
| **ä¸‹è¼‰ TinyLlama PyTorch** | `python scripts/download_hf_model.py --repo-id "TinyLlama/TinyLlama-1.1B-Chat-v1.0"` |
| **ä¸‹è¼‰ä»»æ„æ¨¡å‹** | `python scripts/download_hf_model.py --repo-id "{YOUR_REPO_ID}"` |
| **æŒ‡å®šä¿å­˜ä½ç½®** | `python scripts/download_hf_model.py --repo-id "..." --output-path "D:/Models"` |
| **è·³éé©—è­‰** | `python scripts/download_hf_model.py --repo-id "..." --no-verify` |
| **ä½¿ç”¨èœå–®** | `.\scripts\download_model_interactive.ps1` |

---

## â±ï¸ é æœŸä¸‹è¼‰æ™‚é–“

| æ¨¡å‹ | å¤§å° | æ™‚é–“ï¼ˆ10Mbpsï¼‰ |
|------|------|-----------------|
| TinyLlama PyTorch | 2.2GB | ~30 åˆ†é˜ |
| OpenLLaMA 7B | 3.5GB | ~50 åˆ†é˜ |
| Qwen 7B | 3.8GB | ~55 åˆ†é˜ |

---

## ğŸ“‚ ä¸‹è¼‰å®Œæˆå¾Œ

```powershell
# æŸ¥çœ‹å·²ä¸‹è¼‰çš„æ¨¡å‹
ls ./models

# åˆ—å‡ºæ¨¡å‹æ–‡ä»¶
ls ./models/open_llama_7b_v2-int4-ov
```

---

## âŒ å‡ºå•é¡Œæ™‚

```powershell
# æª¢æŸ¥ç¶²çµ¡
Test-NetConnection huggingface.co -Port 443

# æª¢æŸ¥ç£ç›¤ç©ºé–“
Get-Volume

# æª¢æŸ¥è™›æ“¬ç’°å¢ƒ
$env:VIRTUAL_ENV

# å‡ç´šå·¥å…·
pip install --upgrade huggingface_hub
```

---

## ğŸ“– è©³ç´°æ–‡æª”

- [`docs/DOWNLOAD_HF_MODEL_GUIDE.md`](docs/DOWNLOAD_HF_MODEL_GUIDE.md) - å®Œæ•´ä½¿ç”¨æŒ‡å—
- [`docs/setup/STAGE_7_GUIDE_NEW.md`](docs/setup/STAGE_7_GUIDE_NEW.md) - æ¨ç†è¨­ç½®
- [`QUICKSTART.md`](QUICKSTART.md) - å¿«é€Ÿé–‹å§‹

---

## ğŸ¯ ä¸‹ä¸€æ­¥

ä¸‹è¼‰å®Œæˆå¾Œï¼Œä½¿ç”¨æ¨ç†è…³æœ¬ï¼š

```powershell
python scripts/run_inference_simple.py --prompt "Your question"
```

**æ³¨æ„ï¼š** ä¸‹è¼‰çš„ OpenVINO æ¨¡å‹å¯èˆ‡ PyTorch æ¨ç†è…³æœ¬ä¸¦ç”¨ï¼Œå¾…å®˜æ–¹ä¿®å¾©å¾Œå¯ä½¿ç”¨ OpenVINO æ¨ç†ã€‚

---

**ç‰ˆæœ¬ï¼š** 1.0 | **æ—¥æœŸï¼š** 2025-12-30
