# OpenVINO GenAI æ¨¡å‹æŒ‡å—

æœ¬æ–‡æª”èªªæ˜å¦‚ä½•ä¸‹è¼‰ã€è½‰æ›å’Œç®¡ç†æ¨¡å‹ã€‚

## ğŸ”„ æ¨¡å‹è½‰æ›æµç¨‹

OpenVINO GenAI ä½¿ç”¨å°ˆæœ‰çš„ OpenVINO Intermediate Representation (IR) æ ¼å¼ã€‚æ‚¨éœ€è¦å¾ Hugging Face è½‰æ›æ¨¡å‹ã€‚

### å‰ç½®è¦æ±‚

```powershell
pip install optimum[openvino]
```

### åŸºæœ¬è½‰æ›å‘½ä»¤

```powershell
optimum-cli export openvino \
  --model <hugging-face-model-id> \
  --weight-format <format> \
  --output-dir <output-path> \
  --trust-remote-code
```

**åƒæ•¸èªªæ˜ï¼š**
- `--model`: Hugging Face æ¨¡å‹ ID
- `--weight-format`: é‡åŒ–æ ¼å¼ (int4, int8, fp16)
- `--output-dir`: è¼¸å‡ºç›®éŒ„
- `--trust-remote-code`: ä¿¡ä»»é ç«¯ä»£ç¢¼ï¼ˆæŸäº›æ¨¡å‹éœ€è¦ï¼‰

## ğŸ“š å¸¸è¦‹æ¨¡å‹è½‰æ›ç¯„ä¾‹

### æ–‡å­—ç”Ÿæˆæ¨¡å‹

#### TinyLlamaï¼ˆæ¨è–¦é–‹å§‹ä½¿ç”¨ï¼‰
```powershell
optimum-cli export openvino \
  --model TinyLlama/TinyLlama-1.1B-Chat-v1.0 \
  --weight-format int4 \
  --output-dir ./models/TinyLlama-1.1B-int4 \
  --trust-remote-code
```

**ç‰¹æ€§ï¼š**
- å¤§å°ï¼š1.1B åƒæ•¸
- é€Ÿåº¦ï¼šéå¸¸å¿«
- è³ªé‡ï¼šåŸºæœ¬æ¨ç†
- ç”¨é€”ï¼šæ¸¬è©¦å’Œé–‹ç™¼

#### Phi-3ï¼ˆå¾®è»Ÿå°å‹æ¨¡å‹ï¼‰
```powershell
optimum-cli export openvino \
  --model microsoft/phi-3-mini-4k-instruct \
  --weight-format int4 \
  --output-dir ./models/Phi-3-mini-int4 \
  --trust-remote-code
```

**ç‰¹æ€§ï¼š**
- å¤§å°ï¼š3.8B åƒæ•¸
- é€Ÿåº¦ï¼šå¿«
- è³ªé‡ï¼šè‰¯å¥½
- ç”¨é€”ï¼šè¼•é‡ç´šæ‡‰ç”¨

#### Llama 2ï¼ˆä¸­ç­‰è¦æ¨¡ï¼‰
```powershell
optimum-cli export openvino \
  --model meta-llama/Llama-2-7b-chat-hf \
  --weight-format int4 \
  --output-dir ./models/Llama-2-7b-int4 \
  --trust-remote-code
```

**ç‰¹æ€§ï¼š**
- å¤§å°ï¼š7B åƒæ•¸
- é€Ÿåº¦ï¼šä¸­ç­‰
- è³ªé‡ï¼šå„ªç§€
- ç”¨é€”ï¼šé€šç”¨ä»»å‹™
- **æ³¨æ„ï¼š** éœ€è¦ Hugging Face é©—è­‰ token

#### Llama 3ï¼ˆæœ€æ–°ï¼‰
```powershell
optimum-cli export openvino \
  --model meta-llama/Llama-2-13b-chat-hf \
  --weight-format int4 \
  --output-dir ./models/Llama-3-13b-int4 \
  --trust-remote-code
```

### è¦–è¦ºèªè¨€æ¨¡å‹ (VLM)

#### LLaVa
```powershell
optimum-cli export openvino \
  --model llava-hf/llava-1.5-7b-hf \
  --weight-format int4 \
  --output-dir ./models/LLaVa-7b-int4 \
  --trust-remote-code
```

#### MiniCPM-V
```powershell
optimum-cli export openvino \
  --model openbmb/MiniCPM-V \
  --weight-format int4 \
  --output-dir ./models/MiniCPM-V-int4 \
  --trust-remote-code
```

### åœ–åƒç”Ÿæˆæ¨¡å‹

#### Stable Diffusion
```powershell
optimum-cli export openvino \
  --model runwayml/stable-diffusion-v1-5 \
  --weight-format int8 \
  --output-dir ./models/stable-diffusion-v1-5 \
  --trust-remote-code
```

### èªéŸ³æ¨¡å‹

#### Whisper
```powershell
optimum-cli export openvino \
  --model openai/whisper-base \
  --weight-format int8 \
  --output-dir ./models/whisper-base \
  --trust-remote-code
```

### åµŒå…¥æ¨¡å‹

#### BGE Embeddings
```powershell
optimum-cli export openvino \
  --model BAAI/bge-base-zh-v1.5 \
  --weight-format fp16 \
  --output-dir ./models/bge-base-zh-v1.5 \
  --trust-remote-code
```

## ğŸ’¾ æœ¬åœ°æ¨¡å‹ç®¡ç†

### å»ºè­°çš„ç›®éŒ„çµæ§‹

```
models/
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ TinyLlama-1.1B-int4/
â”‚   â”œâ”€â”€ Phi-3-mini-int4/
â”‚   â””â”€â”€ Llama-2-7b-int4/
â”œâ”€â”€ vlm/
â”‚   â”œâ”€â”€ LLaVa-7b-int4/
â”‚   â””â”€â”€ MiniCPM-V-int4/
â”œâ”€â”€ image_generation/
â”‚   â””â”€â”€ stable-diffusion-v1-5/
â”œâ”€â”€ asr/
â”‚   â””â”€â”€ whisper-base/
â””â”€â”€ embedding/
    â””â”€â”€ bge-base-zh-v1.5/
```

### æ¨¡å‹è½‰æ›è…³æœ¬

å»ºè­°ä½¿ç”¨ `scripts/model_converter.py` é€²è¡Œæ‰¹é‡è½‰æ›ï¼š

```powershell
# è½‰æ›å–®å€‹æ¨¡å‹
python scripts/model_converter.py \
  --model "TinyLlama/TinyLlama-1.1B-Chat-v1.0" \
  --output ./models \
  --format int4

# æ‰¹é‡è½‰æ›
python scripts/model_converter.py \
  --models "./config/model_list.txt" \
  --output ./models \
  --format int4
```

## âš™ï¸ é‡åŒ–æ ¼å¼é¸æ“‡

| æ ¼å¼ | å¤§å° | é€Ÿåº¦ | è³ªé‡ | ç”¨é€” |
|------|------|------|------|------|
| FP32 | æœ€å¤§ | æœ€æ…¢ | æœ€ä½³ | åŸºæº–æ¸¬è©¦ã€ç²¾åº¦é©—è­‰ |
| FP16 | 50% | å¿« | å¾ˆå¥½ | è³ªé‡å„ªå…ˆ |
| INT8 | 25% | å¾ˆå¿« | å¥½ | å¹³è¡¡ |
| INT4 | 12.5% | æœ€å¿« | å¯æ¥å— | é€Ÿåº¦å„ªå…ˆã€é‚Šç·£è¨­å‚™ |

**å»ºè­°ï¼š**
- é–‹ç™¼ï¼šINT4ï¼ˆå¿«é€Ÿè¿­ä»£ï¼‰
- ç”Ÿç”¢ï¼šINT8 æˆ– FP16ï¼ˆè³ªé‡å’Œé€Ÿåº¦å¹³è¡¡ï¼‰
- é‚Šç·£è¨­å‚™ï¼šINT4ï¼ˆæœ€å°åŒ–è³‡æºä½¿ç”¨ï¼‰

## ğŸ” Hugging Face é©—è­‰

æŸäº›æ¨¡å‹ï¼ˆå¦‚ Llamaï¼‰éœ€è¦ Hugging Face é©—è­‰ï¼š

```powershell
# è¨­ç½® Hugging Face token
huggingface-cli login

# æˆ–è€…è¨­ç½®ç’°å¢ƒè®Šæ•¸
$env:HF_TOKEN = "your_token_here"
```

## ğŸ“Š æ¨¡å‹æ¨è–¦

### å¿«é€Ÿé–‹å§‹
- **TinyLlama** - 1.1Bï¼Œæœ€å¿«
- ç”¨é€”ï¼šæ¸¬è©¦ç’°å¢ƒã€æ¼”ç¤º

### é€šç”¨ç”¨é€”
- **Phi-3 Mini** - 3.8Bï¼Œå¾ˆå¿«
- **Llama 2 7B** - 7Bï¼Œå¹³è¡¡
- ç”¨é€”ï¼šç”Ÿç”¢æ‡‰ç”¨ã€API æœå‹™

### é«˜è³ªé‡
- **Llama 2 13B** æˆ–æ›´å¤§
- **Mistral 7B**
- ç”¨é€”ï¼šéœ€è¦é«˜è³ªé‡è¼¸å‡º

### è¦–è¦ºä»»å‹™
- **LLaVa 7B** - åœ–åƒç†è§£
- **MiniCPM-V** - è¼•é‡ç´šè¦–è¦º

## ğŸš€ åŠ é€Ÿæ¨¡å‹ä¸‹è¼‰

### ä½¿ç”¨é¡åƒæºï¼ˆä¸­åœ‹ç”¨æˆ¶ï¼‰

```powershell
# è¨­ç½® Hugging Face é¡åƒ
$env:HF_ENDPOINT = "https://hf-mirror.com"

# ç„¶å¾ŒåŸ·è¡Œè½‰æ›å‘½ä»¤
optimum-cli export openvino --model "model-id" ...
```

### ä¸¦è¡Œä¸‹è¼‰

```bash
# ä½¿ç”¨ aria2 åŠ é€Ÿ
aria2c "https://huggingface.co/.../file"
```

## âœ… æ¨¡å‹é©—è­‰

è½‰æ›å¾Œé©—è­‰æ¨¡å‹ï¼š

```powershell
# æ¸¬è©¦æ¨¡å‹æ˜¯å¦å¯åŠ è¼‰
python -c "
import openvino_genai as ov_genai
pipe = ov_genai.LLMPipeline('./models/TinyLlama-1.1B-int4', 'CPU')
print('Model loaded successfully!')
result = pipe.generate('Hello', max_new_tokens=10)
print(result)
"
```

## ğŸ“ æ¨¡å‹åˆ—è¡¨é…ç½®

å»ºè­°ç¶­è­· `config/model_list.txt`ï¼š

```
TinyLlama/TinyLlama-1.1B-Chat-v1.0
microsoft/phi-3-mini-4k-instruct
meta-llama/Llama-2-7b-chat-hf
llava-hf/llava-1.5-7b-hf
BAAI/bge-base-zh-v1.5
```

ç„¶å¾Œæ‰¹é‡è½‰æ›ï¼š

```powershell
python scripts/model_converter.py --models config/model_list.txt --output ./models
```

## ğŸ”— æœ‰ç”¨çš„è³‡æº

- [Hugging Face Model Hub](https://huggingface.co/models)
- [Supported Models by OpenVINO](https://github.com/openvinotoolkit/openvino.genai)
- [Optimum Intel æ–‡æª”](https://huggingface.co/docs/optimum/intel/overview)
- [OpenVINO GenAI Samples](https://github.com/openvinotoolkit/openvino.genai/tree/master/samples)
