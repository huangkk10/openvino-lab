# OpenVINO GenAI è©³ç´°ä½¿ç”¨æŒ‡å—

é€™ä»½æ–‡æª”æä¾› OpenVINO GenAI çš„è©³ç´°åŠŸèƒ½å’Œä½¿ç”¨æ–¹æ³•ã€‚

## ğŸ“¦ å·²å®‰è£çš„å¥—ä»¶

- **openvino-genai** - OpenVINO GenAI ä¸»è¦å¥—ä»¶
- **openvino** - OpenVINO é‹è¡Œæ™‚
- **openvino-tokenizers** - Tokenizer æ”¯æ´
- **optimum[openvino]** - Hugging Face Optimum èˆ‡ OpenVINO æ•´åˆ
- **transformers** - Hugging Face Transformers åº«

## ğŸ¯ æ”¯æ´çš„å ´æ™¯

OpenVINO GenAI æ”¯æ´ä»¥ä¸‹ç”Ÿæˆå¼ AI å ´æ™¯ï¼š

### 1. æ–‡å­—ç”Ÿæˆ
ä½¿ç”¨å¤§èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰é€²è¡Œæ–‡æœ¬ç”Ÿæˆã€å°è©±å’Œå…§å®¹å‰µå»ºã€‚

**æ”¯æ´çš„æ¨¡å‹ï¼š**
- Llama ç³»åˆ—ï¼ˆMeta Llama 2, 3ï¼‰
- Phi ç³»åˆ—ï¼ˆMicrosoft Phiï¼‰
- Qwen ç³»åˆ—ï¼ˆAlibaba Qwenï¼‰
- TinyLlamaï¼ˆå°å‹è¼•é‡ç´šï¼‰
- Mistral
- Gemma

**ç¯„ä¾‹ï¼š**
```python
import openvino_genai as ov_genai

pipe = ov_genai.LLMPipeline("path/to/model", "CPU")
result = pipe.generate("What is artificial intelligence?", max_new_tokens=100)
print(result)
```

### 2. è¦–è¦ºèªè¨€æ¨¡å‹ (VLM)
åˆ†æåœ–åƒå…§å®¹ä¸¦ç”Ÿæˆæè¿°æˆ–å›ç­”è¦–è¦ºç›¸é—œçš„å•é¡Œã€‚

**æ”¯æ´çš„æ¨¡å‹ï¼š**
- LLaVaï¼ˆLarge Language and Vision Assistantï¼‰
- MiniCPM-V
- Qwen-VL

**ç¯„ä¾‹ï¼š**
```python
import openvino_genai as ov_genai
from PIL import Image

pipe = ov_genai.VLMPipeline("path/to/vlm/model", "CPU")
image = Image.open("image.jpg")
result = pipe.generate(image, "Describe this image")
print(result)
```

### 3. åœ–åƒç”Ÿæˆ
ä½¿ç”¨æ“´æ•£æ¨¡å‹ç”Ÿæˆæ–°çš„åœ–åƒã€‚

**æ”¯æ´çš„æ¨¡å‹ï¼š**
- Stable Diffusion
- Flux
- ControlNetï¼ˆæ§åˆ¶åœ–åƒç”Ÿæˆï¼‰

**ç¯„ä¾‹ï¼š**
```python
import openvino_genai as ov_genai

pipe = ov_genai.ImageGenerationPipeline("path/to/model", "CPU")
result = pipe.generate("A cat sitting on a sunny windowsill")
result.save("output.png")
```

### 4. èªéŸ³è­˜åˆ¥ (ASR)
ä½¿ç”¨ Whisper æ¨¡å‹é€²è¡ŒèªéŸ³è½‰æ–‡æœ¬ã€‚

**æ”¯æ´çš„æ¨¡å‹ï¼š**
- OpenAI Whisperï¼ˆå¤šèªè¨€ï¼‰

**ç¯„ä¾‹ï¼š**
```python
import openvino_genai as ov_genai

pipe = ov_genai.ASRPipeline("path/to/whisper/model", "CPU")
result = pipe.infer("audio.wav")
print(result)
```

### 5. èªéŸ³ç”Ÿæˆ (TTS)
ä½¿ç”¨ SpeechT5 é€²è¡Œæ–‡æœ¬è½‰èªéŸ³ã€‚

**æ”¯æ´çš„æ¨¡å‹ï¼š**
- SpeechT5

**ç¯„ä¾‹ï¼š**
```python
import openvino_genai as ov_genai

pipe = ov_genai.TTSPipeline("path/to/speecht5/model", "CPU")
pipe.synthesize("Hello, this is a test", "output.wav")
```

### 6. æ–‡æœ¬åµŒå…¥
ç”Ÿæˆæ–‡æœ¬çš„å‘é‡è¡¨ç¤ºï¼Œç”¨æ–¼èªç¾©æœç´¢ã€‚

**æ”¯æ´çš„æ¨¡å‹ï¼š**
- BERT é¡æ¨¡å‹
- BGE Embedding
- E5

**ç¯„ä¾‹ï¼š**
```python
import openvino_genai as ov_genai

pipe = ov_genai.EmbeddingPipeline("path/to/embedding/model", "CPU")
embedding = pipe.embed("What is OpenVINO?")
print(embedding.shape)  # (1, 768) æˆ–å…¶ä»–ç¶­åº¦
```

### 7. æ–‡æœ¬é‡æ’åº (Reranking)
é‡æ–°è©•ä¼°æœç´¢çµæœçš„ç›¸é—œæ€§ï¼Œç”¨æ–¼ RAG å·¥ä½œæµã€‚

**ç¯„ä¾‹ï¼š**
```python
import openvino_genai as ov_genai

pipe = ov_genai.RerankingPipeline("path/to/reranker/model", "CPU")
scores = pipe.rerank(query, documents)
sorted_docs = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)
```

## ğŸ’¡ æ¨ç†è¨­å‚™é¸æ“‡

OpenVINO æ”¯æ´å¤šç¨®æ¨ç†è¨­å‚™ï¼Œæ‚¨å¯ä»¥æ ¹æ“šç¡¬é«”é¸æ“‡ï¼š

### CPUï¼ˆä¸­å¤®è™•ç†å™¨ï¼‰
- **å„ªé»ï¼š** é€šç”¨ã€å…¼å®¹æ€§å¥½ã€æ˜“æ–¼éƒ¨ç½²
- **ç¼ºé»ï¼š** é€Ÿåº¦ç›¸å°è¼ƒæ…¢
- **é©ç”¨å ´æ™¯ï¼š** ä¸€èˆ¬æ¨ç†ã€é‚Šç·£è¨­å‚™

```python
pipe = ov_genai.LLMPipeline("model_path", "CPU")
```

### GPUï¼ˆåœ–å½¢è™•ç†å™¨ï¼‰
- **å„ªé»ï¼š** é€Ÿåº¦å¿«ã€é«˜ååé‡
- **ç¼ºé»ï¼š** éœ€è¦ç‰¹å®šç¡¬é«”ã€åŠŸè€—é«˜
- **é©ç”¨å ´æ™¯ï¼š** å¯¦æ™‚æ¨ç†ã€æ‰¹é‡è™•ç†

```python
pipe = ov_genai.LLMPipeline("model_path", "GPU")
```

### NPUï¼ˆç¥ç¶“è™•ç†å™¨ï¼‰
- **å„ªé»ï¼š** èƒ½æ•ˆé«˜ã€ä½åŠŸè€—
- **ç¼ºé»ï¼š** é™åˆ¶æ–¼ç‰¹å®šç¡¬é«”ï¼ˆIntel AI Boostï¼‰
- **é©ç”¨å ´æ™¯ï¼š** é‚Šç·£è¨­å‚™ã€ç§»å‹•æ‡‰ç”¨

```python
pipe = ov_genai.LLMPipeline("model_path", "NPU")
```

### å¤šè¨­å‚™çµ„åˆ
```python
# æ··åˆä½¿ç”¨å¤šå€‹è¨­å‚™
pipe = ov_genai.LLMPipeline("model_path", "CPU_GPU")
```

## âš™ï¸ æ¨ç†å„ªåŒ–

### é‡åŒ– (Quantization)
æ¸›å°‘æ¨¡å‹å¤§å°å’Œè¨ˆç®—é‡ã€‚

**æ”¯æ´çš„é‡åŒ–æ ¼å¼ï¼š**
- INT8 é‡åŒ–
- INT4 é‡åŒ–ï¼ˆæ›´æ¿€é€²çš„å£“ç¸®ï¼‰
- FP16 ç²¾åº¦

**ç¯„ä¾‹ï¼ˆæ¨¡å‹è½‰æ›æ™‚ï¼‰ï¼š**
```bash
# INT4 é‡åŒ–ï¼ˆæ¨è–¦ï¼‰
optimum-cli export openvino --model "model-id" --weight-format int4 --output-dir ./model_int4

# INT8 é‡åŒ–
optimum-cli export openvino --model "model-id" --weight-format int8 --output-dir ./model_int8
```

### æ‰¹é‡æ¨ç†
åŒæ™‚è™•ç†å¤šå€‹è¼¸å…¥ä»¥æé«˜ååé‡ã€‚

```python
prompts = [
    "What is AI?",
    "Explain machine learning.",
    "Tell me about neural networks."
]

pipe = ov_genai.LLMPipeline("model_path", "CPU")
results = pipe.generate(prompts, max_new_tokens=50)
for prompt, result in zip(prompts, results):
    print(f"Q: {prompt}\nA: {result}\n")
```

### çºŒé… (Prefix Caching)
å¿«å–å¸¸ç”¨çš„å‰ç¶´ä»¥åŠ å¿«æ¨ç†é€Ÿåº¦ã€‚

```python
# ç³»çµ±æç¤ºè©
system_prompt = "You are a helpful AI assistant."

pipe = ov_genai.LLMPipeline("model_path", "CPU")

# é¦–æ¬¡è«‹æ±‚æœƒç·©å­˜å‰ç¶´
result1 = pipe.generate(system_prompt + "What is Python?")

# å¾ŒçºŒè«‹æ±‚é‡ç”¨ç·©å­˜
result2 = pipe.generate(system_prompt + "What is Java?")
```

## ğŸ”§ å¸¸è¦‹é…ç½®

### ç’°å¢ƒè®Šæ•¸

```bash
# æ—¥èªŒç´šåˆ¥
export OV_LOG_LEVEL=DEBUG

# ç·šç¨‹æ•¸
export OV_NUM_THREADS=4

# GPU é¸æ“‡
export OV_GPU_DEVICE=0
```

### è¶…åƒæ•¸

```python
# æ¨ç†åƒæ•¸
generate_kwargs = {
    "max_new_tokens": 100,        # æœ€å¤šç”Ÿæˆ 100 å€‹ token
    "top_k": 50,                  # Top-K æ¡æ¨£
    "top_p": 0.9,                 # Top-P (nucleus) æ¡æ¨£
    "temperature": 0.7,           # æº«åº¦ï¼ˆæ§åˆ¶éš¨æ©Ÿæ€§ï¼‰
    "do_sample": True,            # æ˜¯å¦ä½¿ç”¨æ¡æ¨£
    "repetition_penalty": 1.1,    # é‡è¤‡æ‡²ç½°
    "num_beams": 1,               # Beam search å¯¬åº¦
}

pipe = ov_genai.LLMPipeline("model_path", "CPU")
result = pipe.generate("Your prompt", **generate_kwargs)
```

## ğŸ“Š æ€§èƒ½æœ€ä½³å¯¦è¸

1. **ä½¿ç”¨é©ç•¶çš„é‡åŒ–æ ¼å¼**
   - INT4 æœ€æ¿€é€²ï¼Œé€Ÿåº¦å¿«
   - INT8 å¹³è¡¡è³ªé‡å’Œé€Ÿåº¦
   - FP16 ä¿æŒè³ªé‡

2. **é¸æ“‡åˆé©çš„è¨­å‚™**
   - CPUï¼šé€šç”¨ã€ä½åŠŸè€—
   - GPUï¼šé€Ÿåº¦å¿«ã€é«˜åå
   - NPUï¼šèƒ½æ•ˆé«˜

3. **æ‰¹é‡è™•ç†**
   - ä¸€æ¬¡è™•ç†å¤šå€‹è«‹æ±‚ä»¥æé«˜æ•ˆç‡

4. **å¿«å–å’Œé ç†±**
   - ä½¿ç”¨çºŒé…å¿«å–å¸¸ç”¨å‰ç¶´
   - ç¬¬ä¸€å€‹æ¨ç†å¯èƒ½è¼ƒæ…¢ï¼ˆå³æ™‚ç·¨è­¯ï¼‰

5. **ç›£æ§è³‡æº**
   - ç›£æ§ CPU/GPU ä½¿ç”¨ç‡
   - é©ç•¶èª¿æ•´ç·šç¨‹æ•¸

## ğŸ”— ç›¸é—œè³‡æº

- [Hugging Face Models](https://huggingface.co/models)
- [Optimum Intel æ–‡æª”](https://huggingface.co/docs/optimum/intel/overview)
- [OpenVINO å®˜æ–¹æ”¯æ´çš„æ¨¡å‹](https://github.com/openvinotoolkit/openvino.genai/blob/master/README.md)
