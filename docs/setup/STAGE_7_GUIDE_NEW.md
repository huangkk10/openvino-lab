# Stage 7ï¸âƒ£ - æ¨ç†è¨­ç½®å’Œä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¦½

**ç›®æ¨™ï¼š** è¨­ç½®ä¸¦é‹è¡Œ TinyLlama æ¨¡å‹æ¨ç†

**æ‰€éœ€æ™‚é–“ï¼š** 
- å¿«é€Ÿé–‹å§‹ï¼š2-3 åˆ†é˜ï¼ˆé¦–æ¬¡è‡ªå‹•ä¸‹è¼‰æ¨¡å‹ ~2.2GBï¼‰
- å®Œæ•´è¨­ç½®ï¼š5-10 åˆ†é˜

**æ ¸å¿ƒå·¥å…·ï¼š**
- `run_inference_simple.py` - **æ¨è–¦** - æ¨™æº–æ¨ç†è…³æœ¬ï¼ˆé–‹ç®±å³ç”¨ï¼‰
- `prepare_models.ps1` - å¯é¸ - ä¸‹è¼‰ OpenVINO å„ªåŒ–æ¨¡å‹ï¼ˆç”¨æ–¼æœªä¾†å…¼å®¹æ€§ï¼‰

---

## ğŸš€ å¿«é€Ÿé–‹å§‹ï¼ˆæ¨è–¦ï¼‰

### æ­¥é©Ÿ 1ï¼šæ¿€æ´»è™›æ“¬ç’°å¢ƒ

```powershell
cd c:\Users\svd\codes\openvino-lab
.\venv\Scripts\Activate.ps1
```

âœ… æ‚¨æ‡‰è©²çœ‹åˆ° `(venv)` å‰ç¶´

### æ­¥é©Ÿ 2ï¼šé‹è¡Œæ¨ç†

#### æ–¹å¼ Aï¼šå–®æ¬¡æ¨ç†ï¼ˆå¿«é€Ÿæ¸¬è©¦ï¼‰

```powershell
python scripts/run_inference_simple.py --prompt "What is machine learning?"
```

#### æ–¹å¼ Bï¼šäº¤äº’å¼æ¨¡å¼ï¼ˆæ¨è–¦ï¼‰

```powershell
python scripts/run_inference_simple.py
```

ç„¶å¾Œè¼¸å…¥ä»»ä½•å•é¡Œï¼Œè¼¸å…¥ `exit` é€€å‡ºã€‚

#### æ–¹å¼ Cï¼šæ¼”ç¤ºæ¨¡å¼

```powershell
python scripts/run_inference_simple.py demo
```

---

## ğŸ“¦ ä½¿ç”¨çš„æ¨¡å‹

### æ¨è–¦æ¨¡å‹ï¼ˆç•¶å‰ä½¿ç”¨ï¼‰

**æ¨¡å‹åç¨±**ï¼š`TinyLlama/TinyLlama-1.1B-Chat-v1.0`

| é …ç›® | è©³æƒ… |
|------|------|
| **æ ¼å¼** | PyTorch (.safetensors) |
| **å¤§å°** | 1.1B åƒæ•¸ |
| **ä¸‹è¼‰å¤§å°** | ~2.2GB |
| **ä¾†æº** | HuggingFace å®˜æ–¹ |
| **æ¨ç†æ–¹å¼** | æ¨™æº– Transformers |
| **ä¸‹è¼‰ä½ç½®** | `~/.cache/huggingface/hub/` |
| **ç‹€æ…‹** | âœ… **æ­£åœ¨ä½¿ç”¨** |

**å„ªé»**ï¼š
- âœ… é–‹ç®±å³ç”¨
- âœ… é¦–æ¬¡è‡ªå‹•ä¸‹è¼‰
- âœ… å…¼å®¹æ€§å¥½

### å¯é¸ï¼šOpenVINO å„ªåŒ–æ¨¡å‹

```powershell
.\scripts\prepare_models.ps1
```

**å¯ç”¨ç‰ˆæœ¬**ï¼š
- `TinyLlama-1.1B-Chat-int4` - 600MB
- `TinyLlama-1.1B-Chat-int8` - 800MB  
- `TinyLlama-1.1B-Chat-fp16` - 1.2GB

**ç‹€æ…‹**ï¼šå·²ä¸‹è¼‰ä½†æœªä½¿ç”¨ï¼ˆç­‰å¾… OpenVINO GenAI å…¼å®¹æ€§ä¿®å¾©ï¼‰

---

## âš™ï¸ é…ç½®èª¿æ•´

### ç·¨è¼¯ `config/.env`

```bash
# æ¨ç†è¨­å‚™
DEFAULT_DEVICE=CPU              # é¸é …ï¼šCPU, GPU, NPU

# æ¨ç†åƒæ•¸
MAX_NEW_TOKENS=100             # æœ€å¤§ç”Ÿæˆä»¤ç‰Œæ•¸
TEMPERATURE=0.7                # æº«åº¦ï¼ˆ0-1ï¼Œè¶Šä½è¶Šç¢ºå®šï¼‰
TOP_P=0.9                      # Top-P æ¡æ¨£
TOP_K=50                       # Top-K æ¡æ¨£
```

### å‘½ä»¤è¡Œèª¿æ•´

```powershell
# ä½¿ç”¨ GPU
python scripts/run_inference_simple.py --device GPU

# å¢åŠ è¼¸å‡ºé•·åº¦
python scripts/run_inference_simple.py --max-tokens 200

# æ›´ç¢ºå®šçš„å›ç­”
# ç·¨è¼¯ config/.envï¼Œè¨­ç½® TEMPERATURE=0.3
```

---

## ğŸ“ æ¨¡å‹ä½ç½®

### è‡ªå‹•ä¸‹è¼‰çš„æ¨¡å‹

```
~/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/
```

åœ¨ Windowsï¼š`C:\Users\svd\.cache\huggingface\hub\...`

### å¯é¸çš„ OpenVINO æ¨¡å‹

```
./models/TinyLlama-1.1B-Chat-int4/
./models/TinyLlama-1.1B-Chat-int8/
./models/TinyLlama-1.1B-Chat-fp16/
```

---

## ğŸ› æ•…éšœæ’é™¤

### âŒ ä¸‹è¼‰æ…¢

```powershell
$env:HF_ENDPOINT="https://hf-mirror.com"
python scripts/run_inference_simple.py --prompt "test"
```

### âŒ æ¨ç†æ…¢

å¦‚æœæœ‰ CUDA GPUï¼Œä½¿ç”¨ GPUï¼š
```powershell
python scripts/run_inference_simple.py --device GPU
```

### âŒ è¨˜æ†¶é«”ä¸è¶³

æ¸›å°‘è¼¸å‡ºé•·åº¦ï¼š
```powershell
python scripts/run_inference_simple.py --max-tokens 50
```

---

## ğŸ“Š æ€§èƒ½é æœŸ

### CPU
- é¦–æ¬¡åŠ è¼‰ï¼š10-15 ç§’
- æ¨ç†é€Ÿåº¦ï¼š20-50 è©/ç§’
- è¨˜æ†¶é«”ï¼š~3GB

### GPUï¼ˆå¦‚æœæœ‰ CUDAï¼‰
- é¦–æ¬¡åŠ è¼‰ï¼š5-10 ç§’
- æ¨ç†é€Ÿåº¦ï¼š100-300 è©/ç§’
- è¨˜æ†¶é«”ï¼š~2-3GB VRAM

---

## ğŸ”— å¿«é€Ÿå‘½ä»¤

```powershell
# æ¿€æ´»ç’°å¢ƒ
.\venv\Scripts\Activate.ps1

# å–®æ¬¡æ¨ç†
python scripts/run_inference_simple.py --prompt "Your question"

# äº¤äº’å¼æ¨¡å¼
python scripts/run_inference_simple.py

# æ¼”ç¤º
python scripts/run_inference_simple.py demo

# ä½¿ç”¨ GPU
python scripts/run_inference_simple.py --device GPU

# ä¸‹è¼‰ OpenVINO æ¨¡å‹ï¼ˆå¯é¸ï¼‰
.\scripts\prepare_models.ps1
```

---

## âœ… å®Œæˆæª¢æŸ¥è¡¨

- [ ] è™›æ“¬ç’°å¢ƒå·²æ¿€æ´»
- [ ] é‹è¡Œäº†æ¨ç†è…³æœ¬
- [ ] æ¨¡å‹å·²ä¸‹è¼‰
- [ ] æ¨ç†çµæœæ­£å¸¸
- [ ] ï¼ˆå¯é¸ï¼‰èª¿æ•´äº†åƒæ•¸

å…¨éƒ¨å®Œæˆï¼ŸğŸ‰ **æ¨ç†ç’°å¢ƒå·²è¨­ç½®å®Œæˆï¼**
